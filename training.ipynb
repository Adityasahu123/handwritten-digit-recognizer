{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTalXbAR-GLm",
        "outputId": "ae8ce6c1-1a3c-49c3-c579-5c625362df54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "2RBvUMxIBO8z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jcprogjava/handwritten-digits-dataset-not-in-mnist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFWbZjGGBTg7",
        "outputId": "fcd6e2bb-aa46-4b9b-c564-422876aece92"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jcprogjava/handwritten-digits-dataset-not-in-mnist\n",
            "License(s): CC-BY-SA-4.0\n",
            "Downloading handwritten-digits-dataset-not-in-mnist.zip to /content\n",
            "  0% 0.00/54.6M [00:00<?, ?B/s]\n",
            "100% 54.6M/54.6M [00:00<00:00, 1.76GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q handwritten-digits-dataset-not-in-mnist.zip -d data\n",
        "!ls data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQDnWLtdBkX8",
        "outputId": "af556a77-aa7b-4aba-e09d-335f4400d12c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "DATA_DIR = \"data/dataset\"\n",
        "IMG_SIZE = (28, 28)\n",
        "BATCH = 64\n",
        "SEED = 42\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"grayscale\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"grayscale\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "def normalize(x, y):\n",
        "    return tf.cast(x, tf.float32) / 255.0, y\n",
        "\n",
        "train_ds = train_ds.map(normalize).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(normalize).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(32,3,activation=\"relu\",padding=\"same\"),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64,3,activation=\"relu\",padding=\"same\"),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=8)\n",
        "\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "model.save(\"model/digit_cnn.keras\")\n",
        "\n",
        "print(\"✅ Training done, model saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCKJkgViBkiJ",
        "outputId": "4e5f444e-a89c-4ec4-926e-14e17a2960db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107730 files belonging to 10 classes.\n",
            "Using 86184 files for training.\n",
            "Found 107730 files belonging to 10 classes.\n",
            "Using 21546 files for validation.\n",
            "Epoch 1/8\n",
            "\u001b[1m1347/1347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.1002 - loss: 2.3026 - val_accuracy: 0.0969 - val_loss: 2.3027\n",
            "Epoch 2/8\n",
            "\u001b[1m1347/1347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.0989 - loss: 2.3027 - val_accuracy: 0.0969 - val_loss: 2.3027\n",
            "Epoch 3/8\n",
            "\u001b[1m1347/1347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.1005 - loss: 2.3028 - val_accuracy: 0.0969 - val_loss: 2.3027\n",
            "Epoch 4/8\n",
            "\u001b[1m1347/1347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.0999 - loss: 2.3028 - val_accuracy: 0.0969 - val_loss: 2.3027\n",
            "Epoch 5/8\n",
            "\u001b[1m1347/1347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.1003 - loss: 2.3028 - val_accuracy: 0.0969 - val_loss: 2.3027\n",
            "Epoch 6/8\n",
            "\u001b[1m1347/1347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.1006 - loss: 2.3027 - val_accuracy: 0.0969 - val_loss: 2.3027\n",
            "Epoch 7/8\n",
            "\u001b[1m1347/1347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.0990 - loss: 2.3028 - val_accuracy: 0.0969 - val_loss: 2.3027\n",
            "Epoch 8/8\n",
            "\u001b[1m1347/1347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.1000 - loss: 2.3028 - val_accuracy: 0.1004 - val_loss: 2.3027\n",
            "✅ Training done, model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r digit_app_files.zip model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea9BaVy7Ck6T",
        "outputId": "cc5766a3-c5bf-416d-fe08-7c055926d230"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/digit_cnn.keras (deflated 69%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"digit_app_files.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EAdaX_xyClDQ",
        "outputId": "ad9b97db-e630-42d3-a633-6ceb6acc7dc0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dc1ed21b-3066-44a0-ad13-4b896341dde9\", \"digit_app_files.zip\", 1561466)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}